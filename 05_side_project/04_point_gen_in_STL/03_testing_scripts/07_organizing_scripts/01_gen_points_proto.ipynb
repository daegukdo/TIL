{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복해서 simulation point를 만드는 script 구현\n",
    "\n",
    " - 입력 : STL points, vertex, plane, normal vector,40 point (.npy), number of iter. (int)\n",
    " - 출력 : txt * number of iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_vertex_index(point40_on_STL, vertex_data):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    points = [[x0, y0, z0], ... [xn, yn, zn]]\n",
    "    vertex_data = [[[px00, py00, pz00], [px01, py01, pz01], [px02, py02, pz02]],\n",
    "                    ...,\n",
    "                   [[pxm0, pym0, pzm0], [pxm1, pym1, pzm1], [pxm2, pym2, pzm2]]]\n",
    "                   \n",
    "    output data structure\n",
    "    selected_index = [i0, i1, ... in]\n",
    "    \"\"\"\n",
    "    \n",
    "    vertex_group                  = []\n",
    "\n",
    "    for i in range(len(point40_on_STL)):\n",
    "        temp                      = []\n",
    "        for j in range(len(vertex_data)):\n",
    "            if point40_on_STL[i] in vertex_data[j]:\n",
    "                temp.append(j)\n",
    "        vertex_group.append(temp)\n",
    "\n",
    "    vertex_selected_index         = []\n",
    "\n",
    "    for i in range(len(vertex_group)):\n",
    "        randomIndex               = random.choice(vertex_group[i])\n",
    "        vertex_selected_index.append(randomIndex)\n",
    "        \n",
    "    return vertex_selected_index, vertex_group\n",
    "\n",
    "def random_vector(length = 1):\n",
    "    \"\"\"\n",
    "    make vector that have length in sphere\n",
    "    \n",
    "    input data structure\n",
    "    vector length = int\n",
    "    \n",
    "    output data structure\n",
    "    vector = [vx, vy, vz]\n",
    "    \"\"\"\n",
    "    \n",
    "    rand_i, rand_j = np.random.rand(2)            # Two independent random numbers from a uniform distribution in the range (0, 1)\n",
    "    theta          = 2 * np.pi * rand_i           # Spherical coordinate theta\n",
    "    phi            = np.arccos(2 * rand_j - 1)    # Spherical coordinate phi, corrected for distribution bias\n",
    "    x              = np.cos(theta) * np.sin(phi)  # Cartesian coordinate x\n",
    "    y              = np.sin(theta) * np.sin(phi)  # Cartesian coordinate y\n",
    "    z              = np.cos(phi)                  # Cartesian coordinate z\n",
    "    vector         = [x * length, y * length, z * length]\n",
    "    # print(vector)\n",
    "\n",
    "    return vector\n",
    "\n",
    "def add_mm_error_to_point(point, max_error = 20):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    point = [x, y, z] # x, y, z unit = mm\n",
    "    \n",
    "    output data structure\n",
    "    point_added_error = [x', y', z']\n",
    "    \"\"\"\n",
    "    \n",
    "    point_added_error      = point.copy()\n",
    "    \n",
    "    error                  = random.uniform(0, max_error)\n",
    "    \n",
    "    xyz_error              = random_vector(error)\n",
    "\n",
    "    point_added_error[0]   += xyz_error[0]\n",
    "    point_added_error[1]   += xyz_error[1]\n",
    "    point_added_error[2]   += xyz_error[2]\n",
    "    \n",
    "    return point_added_error\n",
    "\n",
    "def find_projection_point_in_plane_3D(point, plane, norm_vect):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    point = [x, y, z]\n",
    "    plane = [a, b, c, d] # plane eq. = ax + by + cz + d = 0\n",
    "    norm_vect = [i, j, k]\n",
    "    \n",
    "    output data structure\n",
    "    True -> projected_point = [x', y', z']\n",
    "    False -> value of diff. with plane = float(d)\n",
    "    \"\"\"\n",
    "    \n",
    "    plane_ABC_sqrt       = math.sqrt(plane[0]*plane[0] + plane[1]*plane[1] + plane[2]*plane[2])\n",
    "    dist                 = (plane[3] + plane[0] * point[0] + plane[1] * point[1] + plane[2] * point[2]) / plane_ABC_sqrt\n",
    "    # print(dist)\n",
    "    projected_point      = point - dist * norm_vect\n",
    "    \n",
    "    on_the_plane_value   = is_including_point(plane, projected_point)\n",
    "    \n",
    "    if on_the_plane_value:\n",
    "        pass\n",
    "    else:\n",
    "        print(projected_point)\n",
    "        # print(on_the_plane_value)\n",
    "     \n",
    "    return projected_point \n",
    "\n",
    "def is_including_point(plane, point):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    point = [x, y, z]\n",
    "    plane = [a, b, c, d] # plane eq. = ax + by + cz + d = 0\n",
    "    \n",
    "    output data structure\n",
    "    is point included in plane = bool\n",
    "    \"\"\"\n",
    "    \n",
    "    a                 = plane[0]\n",
    "    b                 = plane[1]\n",
    "    c                 = plane[2]\n",
    "    d                 = plane[3]\n",
    "    x                 = point[0]\n",
    "    y                 = point[1]\n",
    "    z                 = point[2]\n",
    "    \n",
    "    included_value    = a*x + b*y + c*z + d\n",
    "    # print(included_value)\n",
    "    \n",
    "    if included_value < 0.00001:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def cal_points40_with_error_on_plane(point40_on_STL, plane_selected, vector_selected):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    points = [[xr0, yr0, zr0], ... [xrn, yrn, zrn]]\n",
    "    plane_data = [[a0, b0, c0, d0], [a1, b1, c1, d1], ... [am, bm, cm, dm]]\n",
    "    vector_data = [[vx0, vy0, vz0], ... [vxn, vyn, vzn]]\n",
    "    \n",
    "    output data structure (closet points in trg_points from ref_points)\n",
    "    points_on_plane = [[xpr0, ypr0, zpr0], ... [xprn, yprn, zprn]]\n",
    "    \"\"\"\n",
    "    \n",
    "    points40_with_error_on_plane    = []\n",
    "\n",
    "    data_point_40_slt               = point40_on_STL.copy()\n",
    "\n",
    "    for i in range(len(data_point_40_slt)):        \n",
    "        _point_added_error          = add_mm_error_to_point(data_point_40_slt[i])\n",
    "        _point_on_plane             = find_projection_point_in_plane_3D(_point_added_error, \n",
    "                                                                        plane_selected[i],\n",
    "                                                                        vector_selected[i])\n",
    "        \n",
    "        if np.isnan(np.sum(_point_on_plane)):\n",
    "            points40_with_error_on_plane.append(data_point_40_slt[i])\n",
    "        else:\n",
    "            points40_with_error_on_plane.append(_point_on_plane)\n",
    "            \n",
    "    return points40_with_error_on_plane\n",
    "\n",
    "def get_dist_btw_2_3Dpoints(point1, point2):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    point1 = [x1, y1, z1]\n",
    "    point2 = [x2, y2, z2]\n",
    "    \n",
    "    output data structure\n",
    "    distance\n",
    "    \"\"\"\n",
    "    \n",
    "    sum        = 0\n",
    "    for i in range(3):\n",
    "        sum    = sum + (point1[i] - point2[i])**2\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "def get_closet_points(ref_points, trg_points):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    ref_points = [[xr0, yr0, zr0], ... [xrn, yrn, zrn]]\n",
    "    trg_points = [[xt0, yt0, zt0], ... [xtm, ytm, ztm]]\n",
    "    \n",
    "    output data structure (closet points in trg_points from ref_points)\n",
    "    closet_points = [[xc0, yc0, zc0], ... [xcn, ycn, zcn]]\n",
    "    \"\"\"\n",
    "    \n",
    "    tree                         = KDTree(trg_points)\n",
    "    nearest_dist, nearest_ind    = tree.query(ref_points, k=2)\n",
    "    \n",
    "    nearest_index                = nearest_ind[:,1]\n",
    "    closet_points                = []\n",
    "    \n",
    "    for i in range(len(nearest_index)):\n",
    "        closet_points.append(trg_points[nearest_index[i]])\n",
    "        \n",
    "    return closet_points\n",
    "    \n",
    "def get_data_with_index(index_data, some_data):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    index_data = [i0, i1, ... in]\n",
    "    some_data = plane_data or vertex_data or vector_data\n",
    "    plane_data = [[a0, b0, c0, d0], [a1, b1, c1, d1], ... [am, bm, cm, dm]]\n",
    "    vertex_data = [[[px00, py00, pz00], [px01, py01, pz01], [px02, py02, pz02]],\n",
    "                    ...,\n",
    "                   [[pxm0, pym0, pzm0], [pxm1, pym1, pzm1], [pxm2, pym2, pzm2]]]\n",
    "    vector_data = [[vx0, vy0, vz0], ... [vxm, vym, vzm]]\n",
    "    \n",
    "    output data structure\n",
    "    some_data_indexed = plane_data or vertex_data or vector_data\n",
    "    plane_data = [[a0, b0, c0, d0], [a1, b1, c1, d1], ... [an, bn, cn, dn]]\n",
    "    vertex_data = [[[px00, py00, pz00], [px01, py01, pz01], [px02, py02, pz02]],\n",
    "                    ...,\n",
    "                   [[pxn0, pyn0, pzn0], [pxn1, pyn1, pzn1], [pxn2, pyn2, pzn2]]]\n",
    "    vector_data = [[vx0, vy0, vz0], ... [vxn, vyn, vzn]]\n",
    "    \"\"\"\n",
    "    \n",
    "    some_data_indexed = []\n",
    "    \n",
    "    for i in range(len(index_data)):\n",
    "        some_data_indexed.append(some_data[index_data[i]])\n",
    "        \n",
    "    return some_data_indexed\n",
    "    \n",
    "def add_error_to_point_following_to_vector_dirct(point, error_length, vector):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    point = [x, y, z]\n",
    "    error_length = float (int)\n",
    "    vector = [unit x vct, unit y vct, unit z vct]\n",
    "    \n",
    "    output data structure\n",
    "    point_added_error_to_vector_direction = [xe, ye, ze]\n",
    "    \"\"\"\n",
    "    \n",
    "    point_with_error   = []\n",
    "    unit_error         = []\n",
    "    \n",
    "    for i in range(len(point)):\n",
    "        unit_error.append(error_length * vector[i])\n",
    "    \n",
    "    for i in range(len(point)):\n",
    "        point_with_error.append(point[i] + unit_error[i])\n",
    "    \n",
    "    return point_with_error\n",
    "\n",
    "def get_normal_distribution_list(mu, sigma, num_of_list):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    mu = float data\n",
    "    sigma = float data\n",
    "    num_of_list = int data\n",
    "    \n",
    "    output data structure\n",
    "    normal_distribution_list = [n0, n1 ... nm] # m = num_of_list\n",
    "    \"\"\"\n",
    "    \n",
    "    norm_distr_list = []\n",
    "    _mu, _sigma = mu, sigma\n",
    "    norm_distr = []\n",
    "    \n",
    "    while(True):\n",
    "        norm_distr = np.random.normal(_mu, _sigma, 10000)\n",
    "        if(abs(mu - np.mean(norm_distr)) < 0.001):\n",
    "            break\n",
    "            \n",
    "    for i in range(num_of_list):\n",
    "        norm_distr_list.append(random.choice(norm_distr))\n",
    "    \n",
    "    return norm_distr_list\n",
    "\n",
    "def is_data_stable(data_list, thr = 0.5):\n",
    "    \"\"\"\n",
    "    input data structure\n",
    "    data_list = [[xr0, yr0, zr0], ... [xrn, yrn, zrn]]\n",
    "    thr = float data\n",
    "    \n",
    "    output data structure\n",
    "    bool True (if all data have smaller diff. than mean + thr) || Flase\n",
    "    \"\"\"\n",
    "    \n",
    "    data_array = []\n",
    "    if(type(data_list) == type([])):\n",
    "        data_array = np.array(data_list)\n",
    "    elif(type(data_list) == type(np.array([]))):\n",
    "        data_array = data_list\n",
    "    else:\n",
    "        return \"Wrong data type (data_list must be list type or nparray type)\"\n",
    "    \n",
    "    sum_of_point_xyz = [0, 0, 0]\n",
    "    \n",
    "    for i in range(len(data_array)):\n",
    "        for j in range(3):\n",
    "            sum_of_point_xyz[j] += data_array[i][j]\n",
    "            \n",
    "    mean_of_point_xyz = [0, 0, 0]\n",
    "    \n",
    "    for i in range(3):\n",
    "        mean_of_point_xyz[i] = sum_of_point_xyz[i] / float(len(data_array))\n",
    "    \n",
    "    for i in range(len(data_array)):\n",
    "        value = get_dist_btw_2_3Dpoints(mean_of_point_xyz, data_array[i])\n",
    "        # print(value)\n",
    "        if(value < thr):\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 10\n",
    "\n",
    "num_of_files = 8\n",
    "\n",
    "init_points_data_path = 'C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/05_gen_point_init_planing_data/data'\n",
    "\n",
    "STL_info_data_path = 'C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/01_STL_data_to_npy/data'\n",
    "info_data_prefix = ['/Fc1L', '/Tc1L', '/Fc1R', '/Tc1R',\n",
    "                    '/Fc2L', '/Tc2L', '/Fc2R', '/Tc2R']\n",
    "\n",
    "point40_data_path = 'C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/02_raw_40_point/data'\n",
    "\n",
    "point_processed_data_path = 'C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/06_gen_point_data_proto/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/06_gen_point_data_proto/data/Tc1L_0_points_processed\n"
     ]
    }
   ],
   "source": [
    "# !!!\n",
    "test_nof = 1\n",
    "\n",
    "# check file name\n",
    "file_name = point_processed_data_path + info_data_prefix[test_nof] + '_' + str(0) + '_points_processed'\n",
    "print(file_name)\n",
    "\n",
    "# load raw data\n",
    "point_init_plan = np.load(init_points_data_path + info_data_prefix[test_nof] + '_plan.npy')\n",
    "point40_on_STL = np.load(point40_data_path + info_data_prefix[test_nof] + 'points_40_selected.npy')\n",
    "each_point_data = np.load(STL_info_data_path + info_data_prefix[test_nof] + '_femur_each_point_data.npy')\n",
    "vertex_data = np.load(STL_info_data_path + info_data_prefix[test_nof] + '_femur_vertex_data.npy')\n",
    "plane_data = np.load(STL_info_data_path + info_data_prefix[test_nof] + '_femur_plane_data.npy')\n",
    "vector_data = np.load(STL_info_data_path + info_data_prefix[test_nof] + '_femur_vector_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### gen point init PLAN probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select planer init point (on bone model)\n",
    "point_init_plan_on_bone = get_closet_points(point_init_plan, each_point_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen point\n",
    "select_vertex_index_raw_init, _ = select_random_vertex_index(point_init_plan_on_bone, vertex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_init_with_error_on_plane = cal_points40_with_error_on_plane(point_init_plan_on_bone, \n",
    "                                                                  get_data_with_index(select_vertex_index_raw_init, plane_data), \n",
    "                                                                  get_data_with_index(select_vertex_index_raw_init, vector_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_point_init_with_error_on_plane = get_closet_points(point_init_with_error_on_plane, each_point_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_vertex_index_nearest_init, _ = select_random_vertex_index(nearest_point_init_with_error_on_plane, vertex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_point_init_vector = get_data_with_index(select_vertex_index_nearest_init, vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_init_with_uncertainty_error     = []\n",
    "error_value_list                      = get_normal_distribution_list(0, 0.3, len(nearest_point_init_with_error_on_plane))\n",
    "\n",
    "for i in range(len(nearest_point_init_with_error_on_plane)):\n",
    "    error_value                       = error_value_list[i]\n",
    "    tmp_point                         = add_error_to_point_following_to_vector_dirct(nearest_point_init_with_error_on_plane[i],\n",
    "                                                                                     error_value,\n",
    "                                                                                     nearest_point_init_vector[i])\n",
    "\n",
    "    point_init_with_uncertainty_error.append(tmp_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(point_init_with_uncertainty_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_plan.txt\\', \\'w\\') as file:\\n    for i in range(len(point_init_with_uncertainty_error)):\\n        tmp_point = point_init_with_uncertainty_error[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_plan.txt', 'w') as file:\n",
    "    for i in range(len(point_init_with_uncertainty_error)):\n",
    "        tmp_point = point_init_with_uncertainty_error[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### gen point ICP probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen point\n",
    "select_vertex_index_raw, _ = select_random_vertex_index(point40_on_STL, vertex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "points40_with_error_on_plane = cal_points40_with_error_on_plane(point40_on_STL, \n",
    "                                                                get_data_with_index(select_vertex_index_raw, plane_data), \n",
    "                                                                get_data_with_index(select_vertex_index_raw, vector_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_points40_with_error_on_plane = get_closet_points(points40_with_error_on_plane, each_point_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_vertex_index_nearest, _ = select_random_vertex_index(nearest_points40_with_error_on_plane, vertex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_points40_vector = get_data_with_index(select_vertex_index_nearest, vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "points40_with_uncertainty_error     = []\n",
    "error_value_list                    = get_normal_distribution_list(0, 0.3, len(nearest_points40_with_error_on_plane))\n",
    "\n",
    "for i in range(len(nearest_points40_with_error_on_plane)):\n",
    "    error_value                     = error_value_list[i]\n",
    "    tmp_point                       = add_error_to_point_following_to_vector_dirct(nearest_points40_with_error_on_plane[i],\n",
    "                                                                                   error_value,\n",
    "                                                                                   nearest_points40_vector[i])\n",
    "\n",
    "    points40_with_uncertainty_error.append(tmp_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points40_with_uncertainty_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regi_data_points_40 = point_init_with_uncertainty_error + points40_with_uncertainty_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_probing_b40.txt\\', \\'w\\') as file:\\n    for i in range(len(regi_data_points_40)):\\n        tmp_point = regi_data_points_40[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_probing_b40.txt', 'w') as file:\n",
    "    for i in range(len(regi_data_points_40)):\n",
    "        tmp_point = regi_data_points_40[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "points400_with_uncertainty_error   = []\n",
    "\n",
    "for i in range(len(points40_with_uncertainty_error)):\n",
    "    while(True):\n",
    "        tmp                            = []\n",
    "        error_value_list               = get_normal_distribution_list(0, 0.1, 10)\n",
    "        point                          = points40_with_uncertainty_error[i]\n",
    "        for j in range(10):\n",
    "            tmp.append(add_mm_error_to_point(point, abs(error_value_list[j])))\n",
    "        \n",
    "        if is_data_stable(tmp):\n",
    "            for k in range(len(tmp)):\n",
    "                points400_with_uncertainty_error.append(tmp[k])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points400_with_uncertainty_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_probing_400.txt\\', \\'w\\') as file:\\n    for i in range(len(points400_with_uncertainty_error)):\\n        tmp_point = points400_with_uncertainty_error[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_probing_400.txt', 'w') as file:\n",
    "    for i in range(len(points400_with_uncertainty_error)):\n",
    "        tmp_point = points400_with_uncertainty_error[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regi_data_points = point_init_with_uncertainty_error + points400_with_uncertainty_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_all.txt\\', \\'w\\') as file:\\n    for i in range(len(regi_data_points)):\\n        tmp_point = regi_data_points[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_all.txt', 'w') as file:\n",
    "    for i in range(len(regi_data_points)):\n",
    "        tmp_point = regi_data_points[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "points40m_with_uncertainty_error   = []\n",
    "tmp                                = [[], [], []]\n",
    "\n",
    "for i in range(len(points400_with_uncertainty_error)):  \n",
    "    tmp[0].append(points400_with_uncertainty_error[i][0])\n",
    "    tmp[1].append(points400_with_uncertainty_error[i][1])\n",
    "    tmp[2].append(points400_with_uncertainty_error[i][2])\n",
    "    \n",
    "    if(i % 10 == 9):\n",
    "        tmp_point                  = []\n",
    "        tmp_point.append(np.mean(tmp[0]))\n",
    "        tmp_point.append(np.mean(tmp[1]))\n",
    "        tmp_point.append(np.mean(tmp[2]))\n",
    "        points40m_with_uncertainty_error.append(tmp_point)\n",
    "        tmp                        = [[], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points40m_with_uncertainty_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "regi_data_points_m40 = point_init_with_uncertainty_error + points40m_with_uncertainty_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_probing_m40.txt\\', \\'w\\') as file:\\n    for i in range(len(regi_data_points_m40)):\\n        tmp_point = regi_data_points_m40[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_probing_m40.txt', 'w') as file:\n",
    "    for i in range(len(regi_data_points_m40)):\n",
    "        tmp_point = regi_data_points_m40[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### save data with transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulerDegree2mtx(data):\n",
    "    posX = data[0]\n",
    "    posY = data[1]\n",
    "    posZ = data[2]\n",
    "    pitch = data[3] / 180 * 3.141592653589793238462643383279\n",
    "    roll = data[4] / 180 * 3.141592653589793238462643383279\n",
    "    yaw = data[5] / 180 * 3.141592653589793238462643383279\n",
    "    \n",
    "    Rx = np.array([[1, 0, 0, 0],\n",
    "                   [0, math.cos(pitch), -1 * math.sin(pitch), 0],\n",
    "                   [0, math.sin(pitch), math.cos(pitch), 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "    \n",
    "    Ry = np.array([[math.cos(roll), 0, math.sin(roll), 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [-1 * math.sin(roll), 0, math.cos(roll), 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "    \n",
    "    Rz = np.array([[math.cos(yaw), -1 * math.sin(yaw), 0, 0],\n",
    "                   [math.sin(yaw), math.cos(yaw), 0, 0],\n",
    "                   [0, 0, 1, 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "    \n",
    "    mtxR = np.dot(Rz, np.dot(Ry, Rx))\n",
    "    \n",
    "    mtxR[0][3] = posX\n",
    "    mtxR[1][3] = posY\n",
    "    mtxR[2][3] = posZ\n",
    "    \n",
    "    return mtxR\n",
    "\n",
    "def point2mtx(point):\n",
    "    mtx = np.array([[1, 0, 0, point[0]],\n",
    "                    [0, 1, 0, point[1]],\n",
    "                    [0, 0, 1, point[2]],\n",
    "                    [0, 0, 0, 1       ]])\n",
    "    \n",
    "    return mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sim data\n",
    "sim_file_path = \"C:/Users/eornr/Desktop/source_crx/200331_point_gen/01_point_gen_in_STL/06_gen_point_data_proto/sim_pose/\"\n",
    "sim_file_names = [\"left_femur_sim\", \"left_tibia_sim\"]\n",
    "\n",
    "left_femur_position_pose_data_list = np.load(sim_file_path + sim_file_names[0] + '.npy')\n",
    "left_tibia_position_pose_data_list = np.load(sim_file_path + sim_file_names[1] + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FL, TL, FR, TR\n",
    "trns_mtx_list = [left_femur_position_pose_data_list,\n",
    "                 left_tibia_position_pose_data_list,\n",
    "                 [625, -195, 225, 220, 0, 0],\n",
    "                 [625, -195, 225, 200, 0, 180]]\n",
    "\n",
    "transform_data_euler_degree_rot = []\n",
    "\n",
    "if(\"F\" in file_name and \"L\" in file_name):\n",
    "    transform_data_euler_degree_rot = trns_mtx_list[0]\n",
    "elif(\"T\" in file_name and \"L\" in file_name):\n",
    "    transform_data_euler_degree_rot = trns_mtx_list[1]\n",
    "elif(\"F\" in file_name and \"R\" in file_name):\n",
    "    transform_data_euler_degree_rot = trns_mtx_list[2]\n",
    "elif(\"T\" in file_name and \"R\" in file_name):\n",
    "    transform_data_euler_degree_rot = trns_mtx_list[3]\n",
    "\n",
    "transform_data_mtx = []\n",
    "\n",
    "for i in range(len(transform_data_euler_degree_rot)):\n",
    "    transform_data_mtx.append(eulerDegree2mtx(transform_data_euler_degree_rot[i]))\n",
    "\n",
    "for iter_mtx in range(len(transform_data_mtx)):\n",
    "    regi_points_trans = []\n",
    "\n",
    "    for i in range(len(regi_data_points)):\n",
    "        tmp_mtx = np.dot(transform_data_mtx[iter_mtx], point2mtx(regi_data_points[i]))\n",
    "        regi_points_trans.append([tmp_mtx[0][3], \n",
    "                                  tmp_mtx[1][3], \n",
    "                                  tmp_mtx[2][3]])\n",
    "\n",
    "    with open(file_name + '_all_t' + str(iter_mtx) + '.txt', 'w') as file:\n",
    "        for i in range(len(regi_points_trans)):\n",
    "            tmp_point = regi_points_trans[i]\n",
    "            tmp_data_str = \"\"\n",
    "            for j in range(len(tmp_point)):\n",
    "                tmp_data_str += str(tmp_point[j])\n",
    "                if j < 2:\n",
    "                    tmp_data_str += ', '\n",
    "                else:\n",
    "                    tmp_data_str += '\\n'\n",
    "            file.write(tmp_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(file_name + \\'_all_trs.txt\\', \\'w\\') as file:\\n    for i in range(len(regi_points_trans)):\\n        tmp_point = regi_points_trans[i]\\n        tmp_data_str = \"\"\\n        for j in range(len(tmp_point)):\\n            tmp_data_str += str(tmp_point[j])\\n            if j < 2:\\n                tmp_data_str += \\', \\'\\n            else:\\n                tmp_data_str += \\'\\n\\'\\n        file.write(tmp_data_str)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(file_name + '_all_trs.txt', 'w') as file:\n",
    "    for i in range(len(regi_points_trans)):\n",
    "        tmp_point = regi_points_trans[i]\n",
    "        tmp_data_str = \"\"\n",
    "        for j in range(len(tmp_point)):\n",
    "            tmp_data_str += str(tmp_point[j])\n",
    "            if j < 2:\n",
    "                tmp_data_str += ', '\n",
    "            else:\n",
    "                tmp_data_str += '\\n'\n",
    "        file.write(tmp_data_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
