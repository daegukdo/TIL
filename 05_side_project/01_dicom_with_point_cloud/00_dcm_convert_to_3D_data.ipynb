{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read .dcm and save as .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import dicom\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm2npy(in_path, out_path, out_file_name = \"fullimages.npy\"\n",
    "            max_setter = -1024, set_max_setter_value = -1024, \n",
    "            upper_range = -600, lower_range = 500, set_range_value = 1000):\n",
    "    '''\n",
    "    in_path : import dcm 2d stack data path\n",
    "    out_path : export npy data path\n",
    "    out_file_name : set exported file name\n",
    "    max_setter보다 낮은 pixel 값은 모두 set_max_setter_value로 바꿈 ... air 및 CT circle을 지우기 위함\n",
    "    upper_range보다 크고 lower_range보다 작은 사이의 pixel 값을 set_range_value로 바꿈 ... 특정 값을 높이기 위함\n",
    "    '''\n",
    "    data_path = in_path\n",
    "    output_path = out_path\n",
    "    g = glob(data_path + '/*.dcm')\n",
    "    \n",
    "    # Print out the first 5 file names to verify we're in the right folder.\n",
    "    print(\"Total of %d DICOM images.\\nFirst 5 filenames:\" % len(g))\n",
    "    print('\\n'.join(g[:5]))\n",
    "\n",
    "    patient = load_scan(data_path)\n",
    "    imgs = get_pixels_hu(patient\n",
    "                         max_setter, set_max_setter_value,\n",
    "                         upper_range, lower_range, set_range_value)\n",
    "    \n",
    "    output_full_path = output_path + out_file_name\n",
    "    \n",
    "    np.save(output_full_path, imgs)\n",
    "    \n",
    "    imgs_data_dcm_to_npy = np.load(output_full_path)\n",
    "    \n",
    "    return imgs_data_dcm_to_npy\n",
    "\n",
    "def load_scan(path):\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(scans, \n",
    "                  max_setter, set_max_setter_value,\n",
    "                  upper_range, lower_range, set_range_value):\n",
    "    # hounsfield unit\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    \n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    # saturated air in CT\n",
    "    image[image <= max_setter] = set_max_setter_value\n",
    "    image[(image > upper_range) & (image < lower_range)] = set_range_value\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load .npy data and check 2D stack dicom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_stack(stack, rows=6, cols=6, start_with=10, show_every=5):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_data_path = 'C:/Users/dDk13/Desktop/ddk_test/PointCloudTest/data/manekin_data/'\n",
    "out_data_path = '01_export_data/'\n",
    "\n",
    "imgs_dicom_to_process = dcm2npy(dcm_data_path, out_data_path)\n",
    "num_of_dicom_data = len(imgs_dicom_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a image\n",
    "sample_stack(imgs_dicom_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminate half of image (lower)\n",
    "\n",
    " - 환자의 표면부만 검출하고할 때만 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocked_garbage(imgs_to_process):\n",
    "    \n",
    "    upper = np.ndarray(shape=(256,512), dtype=np.int16)\n",
    "    lower = np.ndarray(shape=(256,512), dtype=np.int16)\n",
    "\n",
    "    upper.fill(1)\n",
    "    lower.fill(0)\n",
    "\n",
    "    block_filter = np.concatenate((upper, lower), axis=0)\n",
    "\n",
    "    img_data_blocked = []\n",
    "\n",
    "    for i in range(len(imgs_to_process)):\n",
    "        img_tmp = imgs_dicom_to_process[i]\n",
    "        img_tmp_blocked = img_tmp * block_filter\n",
    "    \n",
    "        img_tmp_blocked[img_tmp_blocked == 0] = -1024\n",
    "    \n",
    "        img_data_blocked.append(img_tmp_blocked)\n",
    "        \n",
    "    return np.array(img_data_blocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_data_blocked = blocked_garbage(imgs_dicom_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a image\n",
    "sample_stack(dcm_data_blocked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contour detection (dilation - find contour - erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import disk, dilation, erosion\n",
    "from skimage import measure\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def contour_detection(imgs_to_process):\n",
    "    num_of_img_data = len(imgs_to_process)\n",
    "    imgs_to_process_dilation = []\n",
    "\n",
    "    for i in range(num_of_img_data):\n",
    "        mask = disk(3)\n",
    "        img = dilation(imgs_to_process[i], selem=mask)\n",
    "        imgs_to_process_dilation.append(img)\n",
    "        \n",
    "    imgs_to_process_contour = []\n",
    "\n",
    "    for i in range(num_of_img_data):\n",
    "\n",
    "        # Construct some test data\n",
    "        r = imgs_to_process_dilation[i]\n",
    "\n",
    "        # Find contours at a constant value of 0.8\n",
    "        contours = measure.find_contours(r, 0.8)\n",
    "\n",
    "        contour_surf = contours[0]\n",
    "\n",
    "        polygon = []\n",
    "\n",
    "        for p in range(len(contour_surf)):\n",
    "            polygon.append((contour_surf[p][1], contour_surf[p][0]))\n",
    "\n",
    "        # polygon = [(x1,y1),(x2,y2),...]\n",
    "        width = 512\n",
    "        height = 512\n",
    "\n",
    "        img = Image.new('L', (width, height), 0)\n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "        mask = np.array(img)\n",
    "\n",
    "        mask_ers = erosion(mask, selem=disk(3))\n",
    "\n",
    "        imgs_to_process_contour.append(mask_ers)\n",
    "    \n",
    "    return np.array(imgs_to_process_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_data_contour = contour_detection(dcm_data_blocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a image\n",
    "sample_stack(dcm_data_contour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make 3D data (.obj and .ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "def make_mesh(image, threshold=-300, step_size=1):\n",
    "\n",
    "    print(\"Transposing surface\")\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    print(\"Calculating surface\")\n",
    "    verts, faces, norm, val = measure.marching_cubes_lewiner(p, threshold, step_size=step_size, allow_degenerate=True) \n",
    "    return verts, faces\n",
    "\n",
    "def make_and_save_mesh_to_obj(image, threshold=-300, step_size=1, slice_thickness=1.0):\n",
    "\n",
    "    print(\"Transposing surface\")\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    print(\"Calculating surface\")\n",
    "    verts, faces, normals, val = measure.marching_cubes_lewiner(p, threshold, spacing=(1.0, 1.0, slice_thickness), \n",
    "                                                                step_size=step_size, allow_degenerate=True) \n",
    "    faces = faces + 1\n",
    "    \n",
    "    thefile = open('test__.obj', 'w')\n",
    "    for item in verts:\n",
    "        thefile.write(\"v {0} {1} {2}\\n\".format(item[0],item[1],item[2]))\n",
    "\n",
    "    for item in normals:\n",
    "        thefile.write(\"vn {0} {1} {2}\\n\".format(item[0],item[1],item[2]))\n",
    "\n",
    "    for item in faces:\n",
    "        thefile.write(\"f {0}//{0} {1}//{1} {2}//{2}\\n\".format(item[0],item[1],item[2]))  \n",
    "\n",
    "    thefile.close()\n",
    "    \n",
    "    print(\"make .obj fin.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def make_and_save_mesh_to_ply(image, threshold=-300, step_size=1, slice_thickness=1.0):\n",
    "\n",
    "    print(\"Transposing surface\")\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    print(\"Calculating surface\")\n",
    "    verts, faces, normals, val = measure.marching_cubes_lewiner(p, threshold, spacing=(1.0, 1.0, slice_thickness), \n",
    "                                                                step_size=step_size, allow_degenerate=True) \n",
    "    \n",
    "    hd_0 = \"ply\\n\"\n",
    "    hd_1 = \"format ascii 1.0\\n\"\n",
    "    hd_2 = \"element vertex {0}\\n\".format(str(len(verts)))\n",
    "    hd_3 = \"property float x\\n\"\n",
    "    hd_4 = \"property float y\\n\"\n",
    "    hd_5 = \"property float z\\n\"\n",
    "    hd_6 = \"end_header\\n\"\n",
    "    \n",
    "    thefile = open('test__.ply', 'w')\n",
    "    \n",
    "    thefile.write(hd_0)\n",
    "    thefile.write(hd_1)\n",
    "    thefile.write(hd_2)\n",
    "    thefile.write(hd_3)\n",
    "    thefile.write(hd_4)\n",
    "    thefile.write(hd_5)\n",
    "    thefile.write(hd_6)\n",
    "    \n",
    "    for item in verts:\n",
    "        thefile.write(\"{0} {1} {2}\\n\".format(item[0],item[1],item[2]))  \n",
    "\n",
    "    thefile.close()\n",
    "    \n",
    "    print(\"make .ply fin.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def plotly_3d(verts, faces):\n",
    "    x,y,z = zip(*verts) \n",
    "    \n",
    "    print(\"Drawing\")\n",
    "    \n",
    "    # Make the colormap single color since the axes are positional not intensity. \n",
    "#    colormap=['rgb(255,105,180)','rgb(255,255,51)','rgb(0,191,255)']\n",
    "    colormap=['rgb(236, 236, 212)','rgb(236, 236, 212)']\n",
    "    \n",
    "    fig = FF.create_trisurf(x=x,\n",
    "                        y=y, \n",
    "                        z=z, \n",
    "                        plot_edges=False,\n",
    "                        colormap=colormap,\n",
    "                        simplices=faces,\n",
    "                        backgroundcolor='rgb(64, 64, 64)',\n",
    "                        title=\"Interactive Visualization\")\n",
    "    iplot(fig)\n",
    "\n",
    "def plt_3d(verts, faces):\n",
    "    print(\"Drawing\")\n",
    "    x,y,z = zip(*verts) \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], linewidths=0.05, alpha=1)\n",
    "    face_color = [1, 1, 0.9]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, max(x))\n",
    "    ax.set_ylim(0, max(y))\n",
    "    ax.set_zlim(0, max(z))\n",
    "    ax.set_facecolor((0.7, 0.7, 0.7))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
